{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zayto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zayto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import itertools\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of symptoms\n",
    "symptoms = ['itching', 'skin_rash', 'nodal_skin_eruptions',\n",
    "            'continuous_sneezing', 'shivering', 'chills', 'joint_pain',\n",
    "            'stomach_pain', 'acidity', 'ulcers_on_tongue', 'muscle_wasting',\n",
    "            'vomiting', 'burning_micturition', 'spotting_ urination',\n",
    "            'fatigue', 'weight_gain', 'anxiety', 'cold_hands_and_feets',\n",
    "            'mood_swings', 'weight_loss', 'restlessness', 'lethargy',\n",
    "            'patches_in_throat', 'irregular_sugar_level', 'cough',\n",
    "            'high_fever', 'sunken_eyes', 'breathlessness', 'sweating',\n",
    "            'dehydration', 'indigestion', 'headache', 'yellowish_skin',\n",
    "            'dark_urine', 'nausea', 'loss_of_appetite', 'pain_behind_the_eyes',\n",
    "            'back_pain', 'constipation', 'abdominal_pain', 'diarrhoea',\n",
    "            'mild_fever', 'yellow_urine', 'yellowing_of_eyes',\n",
    "            'acute_liver_failure', 'fluid_overload', 'swelling_of_stomach',\n",
    "            'swelled_lymph_nodes', 'malaise', 'blurred_and_distorted_vision',\n",
    "            'phlegm', 'throat_irritation', 'redness_of_eyes', 'sinus_pressure',\n",
    "            'runny_nose', 'congestion', 'chest_pain', 'weakness_in_limbs',\n",
    "            'fast_heart_rate', 'pain_during_bowel_movements',\n",
    "            'pain_in_anal_region', 'bloody_stool', 'irritation_in_anus',\n",
    "            'neck_pain', 'dizziness', 'cramps', 'bruising', 'obesity',\n",
    "            'swollen_legs', 'swollen_blood_vessels', 'puffy_face_and_eyes',\n",
    "            'enlarged_thyroid', 'brittle_nails', 'swollen_extremeties',\n",
    "            'excessive_hunger', 'extra_marital_contacts',\n",
    "            'drying_and_tingling_lips', 'slurred_speech', 'knee_pain',\n",
    "            'hip_joint_pain', 'muscle_weakness', 'stiff_neck',\n",
    "            'swelling_joints', 'movement_stiffness', 'spinning_movements',\n",
    "            'loss_of_balance', 'unsteadiness', 'weakness_of_one_body_side',\n",
    "            'loss_of_smell', 'bladder_discomfort', 'foul_smell_of urine',\n",
    "            'continuous_feel_of_urine', 'passage_of_gases', 'internal_itching',\n",
    "            'toxic_look_(typhos)', 'depression', 'irritability', 'muscle_pain',\n",
    "            'altered_sensorium', 'red_spots_over_body', 'belly_pain',\n",
    "            'abnormal_menstruation', 'dischromic _patches',\n",
    "            'watering_from_eyes', 'increased_appetite', 'polyuria',\n",
    "            'family_history', 'mucoid_sputum', 'rusty_sputum',\n",
    "            'lack_of_concentration', 'visual_disturbances',\n",
    "            'receiving_blood_transfusion', 'receiving_unsterile_injections',\n",
    "            'coma', 'stomach_bleeding', 'distention_of_abdomen',\n",
    "            'history_of_alcohol_consumption', 'fluid_overload.1',\n",
    "            'blood_in_sputum', 'prominent_veins_on_calf', 'palpitations',\n",
    "            'painful_walking', 'pus_filled_pimples', 'blackheads', 'scurring',\n",
    "            'skin_peeling', 'silver_like_dusting', 'small_dents_in_nails',\n",
    "            'inflammatory_nails', 'blister', 'red_sore_around_nose',\n",
    "            'yellow_crust_ooze']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "symptoms = ['itching', 'skin_rash', 'nodal_skin_eruptions',\n",
    "            'continuous_sneezing', 'shivering', 'chills', 'joint_pain',\n",
    "            'stomach_pain', 'acidity', 'ulcers_on_tongue', 'muscle_wasting',\n",
    "            'vomiting', 'burning_micturition', 'spotting_ urination',\n",
    "            'fatigue', 'weight_gain', 'anxiety', 'cold_hands_and_feets',\n",
    "            'mood_swings', 'weight_loss', 'restlessness', 'lethargy',\n",
    "            'patches_in_throat', 'irregular_sugar_level', 'cough',\n",
    "            'high_fever', 'sunken_eyes', 'breathlessness', 'sweating',\n",
    "            'dehydration', 'indigestion', 'headache', 'yellowish_skin',\n",
    "            'dark_urine', 'nausea', 'loss_of_appetite', 'pain_behind_the_eyes',\n",
    "            'back_pain', 'constipation', 'abdominal_pain', 'diarrhoea',\n",
    "            'mild_fever', 'yellow_urine', 'yellowing_of_eyes',\n",
    "            'acute_liver_failure', 'fluid_overload', 'swelling_of_stomach',\n",
    "            'swelled_lymph_nodes', 'malaise', 'blurred_and_distorted_vision',\n",
    "            'phlegm', 'throat_irritation', 'redness_of_eyes', 'sinus_pressure',\n",
    "            'runny_nose', 'congestion', 'chest_pain', 'weakness_in_limbs',\n",
    "            'fast_heart_rate', 'pain_during_bowel_movements',\n",
    "            'pain_in_anal_region', 'bloody_stool', 'irritation_in_anus',\n",
    "            'neck_pain', 'dizziness', 'cramps', 'bruising', 'obesity',\n",
    "            'swollen_legs', 'swollen_blood_vessels', 'puffy_face_and_eyes',\n",
    "            'enlarged_thyroid', 'brittle_nails', 'swollen_extremeties',\n",
    "            'excessive_hunger', 'extra_marital_contacts',\n",
    "            'drying_and_tingling_lips', 'slurred_speech', 'knee_pain',\n",
    "            'hip_joint_pain', 'muscle_weakness', 'stiff_neck',\n",
    "            'swelling_joints', 'movement_stiffness', 'spinning_movements',\n",
    "            'loss_of_balance', 'unsteadiness', 'weakness_of_one_body_side',\n",
    "            'loss_of_smell', 'bladder_discomfort', 'foul_smell_of urine',\n",
    "            'continuous_feel_of_urine', 'passage_of_gases', 'internal_itching',\n",
    "            'toxic_look_(typhos)', 'depression', 'irritability', 'muscle_pain',\n",
    "            'altered_sensorium', 'red_spots_over_body', 'belly_pain',\n",
    "            'abnormal_menstruation', 'dischromic _patches',\n",
    "            'watering_from_eyes', 'increased_appetite', 'polyuria',\n",
    "            'family_history', 'mucoid_sputum', 'rusty_sputum',\n",
    "            'lack_of_concentration', 'visual_disturbances',\n",
    "            'receiving_blood_transfusion', 'receiving_unsterile_injections',\n",
    "            'coma', 'stomach_bleeding', 'distention_of_abdomen',\n",
    "            'history_of_alcohol_consumption', 'fluid_overload.1',\n",
    "            'blood_in_sputum', 'prominent_veins_on_calf', 'palpitations',\n",
    "            'painful_walking', 'pus_filled_pimples', 'blackheads', 'scurring',\n",
    "            'skin_peeling', 'silver_like_dusting', 'small_dents_in_nails',\n",
    "            'inflammatory_nails', 'blister', 'red_sore_around_nose',\n",
    "            'yellow_crust_ooze']\n",
    "\n",
    "class Semantic:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        print(text)\n",
    "    def process_text(self):\n",
    "        # Tokenize the text\n",
    "        tokens = nltk.word_tokenize(self.text)\n",
    "\n",
    "        # Remove stop words\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        return [\n",
    "            token\n",
    "            for token in tokens\n",
    "            if token.lower() not in stop_words\n",
    "            and token != '.'\n",
    "            and token != 'bit'\n",
    "            and token != 'little'\n",
    "            and token != 'also'\n",
    "            and token != 'from'\n",
    "            and token != 'suffer'\n",
    "        ]\n",
    "    def get_combinations(self):\n",
    "        filtered_words = self.process_text()\n",
    "        number = 3 if len(filtered_words)>1 else 1\n",
    "        combinations = itertools.combinations(filtered_words, 3)\n",
    "        list_of_combinations= []\n",
    "        # convert the combinations to sentences\n",
    "        for combination in combinations:\n",
    "            sentence = ' '.join(combination)\n",
    "            list_of_combinations.append(sentence)\n",
    "        return list_of_combinations\n",
    "    def getSimilarity(self,extracted_list):  # sourcery skip: remove-redundant-fstring\n",
    "        # create the transform\n",
    "        vectorizer = TfidfVectorizer()\n",
    "    # encode the sentences\n",
    "        vectors = vectorizer.fit_transform(extracted_list)\n",
    "        return cosine_similarity(vectors[0], vectors[1])\n",
    "    def get_symptoms(self):\n",
    "        extracted_symptoms = []\n",
    "        list_of_combinations=self.get_combinations()\n",
    "        for symptom in symptoms:\n",
    "        # check if the symptom is mentioned in the user text\n",
    "            norm_symptom = symptom.replace(\"_\", \" \")\n",
    "            for combin in list_of_combinations:\n",
    "                if (\n",
    "                self.getSimilarity([combin, norm_symptom]) > 0.30\n",
    "                and symptom not in extracted_symptoms\n",
    "            ):\n",
    "                    extracted_symptoms.append(symptom)\n",
    "        return extracted_symptoms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The patient has a fever and a headache,fatigue\n",
      "['fatigue', 'high_fever', 'headache', 'mild_fever']\n"
     ]
    }
   ],
   "source": [
    "sem = Semantic(\"The patient has a fever and a headache,fatigue\")\n",
    "sem.process_text()\n",
    "sem.get_combinations()\n",
    "print(sem.get_symptoms())\n",
    "pickle.dump(sem, open(f'../models/sem', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m semfile\u001b[39m.\u001b[39mclose()\n\u001b[0;32m      4\u001b[0m model\u001b[39m.\u001b[39mtext \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mThe patient suffering from itching skin rash and nodal skin eruptions and continuous sneezing\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39;49mget_symptoms())\n",
      "Cell \u001b[1;32mIn[2], line 96\u001b[0m, in \u001b[0;36mSemantic.get_symptoms\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m     norm_symptom \u001b[39m=\u001b[39m symptom\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m combin \u001b[39min\u001b[39;00m list_of_combinations:\n\u001b[0;32m     95\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m---> 96\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetSimilarity([combin, norm_symptom]) \u001b[39m>\u001b[39m \u001b[39m0.30\u001b[39m\n\u001b[0;32m     97\u001b[0m         \u001b[39mand\u001b[39;00m symptom \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m extracted_symptoms\n\u001b[0;32m     98\u001b[0m     ):\n\u001b[0;32m     99\u001b[0m             extracted_symptoms\u001b[39m.\u001b[39mappend(symptom)\n\u001b[0;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m extracted_symptoms\n",
      "Cell \u001b[1;32mIn[2], line 86\u001b[0m, in \u001b[0;36mSemantic.getSimilarity\u001b[1;34m(self, extracted_list)\u001b[0m\n\u001b[0;32m     84\u001b[0m     vectorizer \u001b[39m=\u001b[39m TfidfVectorizer()\n\u001b[0;32m     85\u001b[0m \u001b[39m# encode the sentences\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     vectors \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mfit_transform(extracted_list)\n\u001b[0;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m cosine_similarity(vectors[\u001b[39m0\u001b[39m], vectors[\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32md:\\pythonProject\\ml\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2121\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2114\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[0;32m   2115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf \u001b[39m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2116\u001b[0m     norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm,\n\u001b[0;32m   2117\u001b[0m     use_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_idf,\n\u001b[0;32m   2118\u001b[0m     smooth_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth_idf,\n\u001b[0;32m   2119\u001b[0m     sublinear_tf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msublinear_tf,\n\u001b[0;32m   2120\u001b[0m )\n\u001b[1;32m-> 2121\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[0;32m   2122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m   2123\u001b[0m \u001b[39m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2124\u001b[0m \u001b[39m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32md:\\pythonProject\\ml\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1390\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[39mif\u001b[39;00m max_features \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1389\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sort_features(X, vocabulary)\n\u001b[1;32m-> 1390\u001b[0m X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_words_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_limit_features(\n\u001b[0;32m   1391\u001b[0m     X, vocabulary, max_doc_count, min_doc_count, max_features\n\u001b[0;32m   1392\u001b[0m )\n\u001b[0;32m   1393\u001b[0m \u001b[39mif\u001b[39;00m max_features \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1394\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sort_features(X, vocabulary)\n",
      "File \u001b[1;32md:\\pythonProject\\ml\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1245\u001b[0m, in \u001b[0;36mCountVectorizer._limit_features\u001b[1;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[0;32m   1241\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(kept_indices) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1242\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1243\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAfter pruning, no terms remain. Try a lower min_df or a higher max_df.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m     )\n\u001b[1;32m-> 1245\u001b[0m \u001b[39mreturn\u001b[39;00m X[:, kept_indices], removed_terms\n",
      "File \u001b[1;32md:\\pythonProject\\ml\\venv\\Lib\\site-packages\\scipy\\sparse\\_index.py:71\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sliceXslice(row, col)\n\u001b[0;32m     70\u001b[0m     \u001b[39melif\u001b[39;00m col\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 71\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_sliceXarray(row, col)\n\u001b[0;32m     72\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mindex results in >2 dimensions\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[39melif\u001b[39;00m row\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32md:\\pythonProject\\ml\\venv\\Lib\\site-packages\\scipy\\sparse\\_csr.py:321\u001b[0m, in \u001b[0;36mcsr_matrix._get_sliceXarray\u001b[1;34m(self, row, col)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_sliceXarray\u001b[39m(\u001b[39mself\u001b[39m, row, col):\n\u001b[1;32m--> 321\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_major_slice(row)\u001b[39m.\u001b[39;49m_minor_index_fancy(col)\n",
      "File \u001b[1;32md:\\pythonProject\\ml\\venv\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:758\u001b[0m, in \u001b[0;36m_cs_matrix._minor_index_fancy\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[39m\"\"\"Index along the minor axis where idx is an array of ints.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    757\u001b[0m idx_dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype\n\u001b[1;32m--> 758\u001b[0m idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(idx, dtype\u001b[39m=\u001b[39midx_dtype)\u001b[39m.\u001b[39mravel()\n\u001b[0;32m    760\u001b[0m M, N \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape)\n\u001b[0;32m    761\u001b[0m k \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(idx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "semfile = open(f'../models/sem', 'rb')\n",
    "model = pickle.load(semfile)\n",
    "semfile.close()\n",
    "model.text = \"The patient suffering from itching skin rash and nodal skin eruptions and continuous sneezing\"\n",
    "print(model.get_symptoms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skin', 'iteching']\n"
     ]
    }
   ],
   "source": [
    "arr = ['skin']\n",
    "ar =['iteching']\n",
    "print(arr + ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0, 9, ..., 6, 5, 2], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Training - Training.csv')\n",
    "\n",
    "# replace lable\n",
    "df.replace({'prognosis':{'Brain and nerves clinic':0,'Dermatology clinic':1,'Ear, nose and throat clinic':2,'Emergency':3,'General clinic':4,\n",
    "'Heart, veins and arteries clinic':5,'Internal clinic':6,'Oncology clinic':7,'Orthopedic clinic':8,'Respiratory clinic':9,'Urology clinic':10, 'Endocrinology clinic':11,'Neurology and brain clinic':12}},inplace=True)\n",
    "#split data\n",
    "X = df.drop('prognosis', axis = 1)\n",
    "y = df['prognosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 40)\n",
    "np.ravel(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itching</th>\n",
       "      <th>skin_rash</th>\n",
       "      <th>nodal_skin_eruptions</th>\n",
       "      <th>continuous_sneezing</th>\n",
       "      <th>shivering</th>\n",
       "      <th>chills</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>stomach_pain</th>\n",
       "      <th>acidity</th>\n",
       "      <th>ulcers_on_tongue</th>\n",
       "      <th>...</th>\n",
       "      <th>blackheads</th>\n",
       "      <th>scurring</th>\n",
       "      <th>skin_peeling</th>\n",
       "      <th>silver_like_dusting</th>\n",
       "      <th>small_dents_in_nails</th>\n",
       "      <th>inflammatory_nails</th>\n",
       "      <th>blister</th>\n",
       "      <th>red_sore_around_nose</th>\n",
       "      <th>yellow_crust_ooze</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Brain and nerves clinic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dermatology clinic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ear, nose and throat clinic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Emergency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Endocrinology clinic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  shivering  \\\n",
       "0        0          0                     0                    1          1   \n",
       "1        0          0                     0                    0          0   \n",
       "2        0          0                     0                    0          0   \n",
       "3        0          0                     0                    0          0   \n",
       "4        0          0                     0                    0          0   \n",
       "\n",
       "   chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  ...  \\\n",
       "0       1           0             0        0                 0  ...   \n",
       "1       0           0             0        0                 0  ...   \n",
       "2       0           0             0        0                 0  ...   \n",
       "3       0           0             0        1                 0  ...   \n",
       "4       1           0             0        0                 0  ...   \n",
       "\n",
       "   blackheads  scurring  skin_peeling  silver_like_dusting  \\\n",
       "0           0         0             0                    0   \n",
       "1           0         0             0                    0   \n",
       "2           0         0             0                    0   \n",
       "3           0         0             0                    0   \n",
       "4           0         0             0                    0   \n",
       "\n",
       "   small_dents_in_nails  inflammatory_nails  blister  red_sore_around_nose  \\\n",
       "0                     0                   0        0                     0   \n",
       "1                     0                   0        0                     0   \n",
       "2                     0                   0        0                     0   \n",
       "3                     0                   0        0                     0   \n",
       "4                     0                   0        0                     0   \n",
       "\n",
       "   yellow_crust_ooze                    prognosis  \n",
       "0                  0      Brain and nerves clinic  \n",
       "1                  0           Dermatology clinic  \n",
       "2                  0  Ear, nose and throat clinic  \n",
       "3                  0                    Emergency  \n",
       "4                  0       Endocrinology clinic    \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease=['Brain and nerves clinic','Dermatology clinic','Ear, nose and throat clinic','Emergency','General clinic',\n",
    "'Heart, veins and arteries clinic','Internal clinic','Oncology clinic ','Orthopedic clinic','Respiratory clinic','Urology clinic ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "for i in range(0,len(symptoms)):\n",
    "    result.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., 10,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train= df[symptoms]\n",
    "\n",
    "y_train = df[[\"prognosis\"]]\n",
    "\n",
    "np.ravel(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.replace({'prognosis':{'Brain and nerves clinic':0,'Dermatology clinic':1,'Ear, nose and throat clinic':2,'Emergency':3,'General clinic':4,\n",
    "'Heart, veins and arteries clinic':5,'Internal clinic':6,'Oncology clinic ':7,'Orthopedic clinic':8,'Respiratory clinic':9,'Urology clinic ':10}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_test\u001b[39m=\u001b[39m test[symptoms]\n\u001b[0;32m      3\u001b[0m y_test \u001b[39m=\u001b[39m test[[\u001b[39m\"\u001b[39m\u001b[39mprognosis\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[0;32m      5\u001b[0m np\u001b[39m.\u001b[39mravel(y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "X_test= test[symptoms]\n",
    "\n",
    "y_test = test[[\"prognosis\"]]\n",
    "\n",
    "np.ravel(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier().fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train score: 100.0\n",
      " Test score: 100.0\n"
     ]
    }
   ],
   "source": [
    "print(f' Train score: {round(forest.score(X_train, y_train), 2) * 100}')\n",
    "print(f' Test score: {round(forest.score(X_test, y_test), 2) * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_predict = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Internal clinic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonProject\\ml\\venv\\Lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\pythonProject\\ml\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:155: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "input_list_encoded = le.fit_transform(disease)\n",
    "print(input_list_encoded)\n",
    "def predict_clinic():\n",
    "    data =['fatigue', 'headache']\n",
    "    for i in range(len(symptoms)):\n",
    "        for k in data:\n",
    "            if(k==symptoms[i]):\n",
    "                result[i]=1\n",
    "    pred = forest.predict([result])\n",
    "    string_value = le.inverse_transform([pred])[0]\n",
    "    return string_value\n",
    "print(predict_clinic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(forest, open(f'../models/forest', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonProject\\ml\\venv\\Lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'headache'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m forest\u001b[39m.\u001b[39;49mpredict([[\u001b[39m'\u001b[39;49m\u001b[39mheadache\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mfatigue\u001b[39;49m\u001b[39m'\u001b[39;49m]])\n",
      "File \u001b[1;32md:\\pythonProject\\ml\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:821\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    801\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    819\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    820\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 821\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    823\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    824\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32md:\\pythonProject\\ml\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:863\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    861\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    862\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    865\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    866\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32md:\\pythonProject\\ml\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:603\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    602\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 603\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    604\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    605\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\pythonProject\\ml\\venv\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    534\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 535\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    536\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    537\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32md:\\pythonProject\\ml\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:877\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    875\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    876\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 877\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    878\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    879\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    880\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    881\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32md:\\pythonProject\\ml\\venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'headache'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dermatology clinic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonProject\\ml\\venv\\Lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "def predict_clinic():\n",
    "    dat = ['itching', 'skin_rash', 'nodal_skin_eruptions', 'continuous_sneezing', 'yellowish_skin', 'skin_peeling']\n",
    "    for i in range(len(symptoms)):\n",
    "        for k in dat:\n",
    "            if(k==symptoms[i]):\n",
    "                result[i]=1\n",
    "\n",
    "    pred = forest.predict([result])\n",
    "    return pred[0]\n",
    "\n",
    "print(predict_clinic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     list_of_combinations \u001b[39m=\u001b[39m get_combinations(res_text, process_text)\n\u001b[0;32m      5\u001b[0m     get_symptoms()\n\u001b[1;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(get_response(\u001b[39m\"\u001b[39;49m\u001b[39mThe patient suffering from itching skin rash and nodal skin eruptions and continuous sneezing\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m, in \u001b[0;36mget_response\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_response\u001b[39m(text):\n\u001b[0;32m      2\u001b[0m     res_text \u001b[39m=\u001b[39m text\n\u001b[1;32m----> 3\u001b[0m     process_text(res_text)\n\u001b[0;32m      4\u001b[0m     list_of_combinations \u001b[39m=\u001b[39m get_combinations(res_text, process_text)\n\u001b[0;32m      5\u001b[0m     get_symptoms()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'process_text' is not defined"
     ]
    }
   ],
   "source": [
    "def get_response(text):\n",
    "    res_text = text\n",
    "    process_text(res_text)\n",
    "    list_of_combinations = get_combinations(res_text, process_text)\n",
    "    get_symptoms()\n",
    "    \n",
    "print(get_response(\"The patient suffering from itching skin rash and nodal skin eruptions and continuous sneezing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:8080\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request,jsonify\n",
    "import pickle\n",
    "app = Flask(__name__)\n",
    "with open('../models/forest', 'rb') as forestFile:\n",
    "    fmodel = pickle.load(forestFile)\n",
    "with open('../models/sem', 'rb') as semFile:\n",
    "    smodel = pickle.load(semFile)\n",
    "@app.route(\"/\",methods=['POST'])\n",
    "def hello():\n",
    "    if request.method == 'POST':\n",
    "        data = request.json\n",
    "    return \"h\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True ,port=8080,use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "347ddf3ceb34605a22ca84c35ba17a556bfa0b014763ce84418f7237b9039da7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
